Model: InceptionNet(
  (stem): Stem(
    (stem): Sequential(
      (0): Conv2d(3, 8, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): Identity()
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    )
  )
  (stages): Sequential(
    (0): InceptionStage(
      (stage): Sequential(
        (0): InceptionBlock(
          (b0): Sequential(
            (0): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): Identity()
            (2): ReLU(inplace=True)
          )
          (b1): Sequential(
            (0): Conv2d(8, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): Identity()
            (2): ReLU(inplace=True)
            (3): FactorisedConv(
              (block): Sequential(
                (0): Conv2d(4, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
                (1): ReLU(inplace=True)
                (2): Conv2d(8, 8, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
                (3): ReLU(inplace=True)
              )
            )
          )
          (b2): Sequential(
            (0): Conv2d(8, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): Identity()
            (2): ReLU(inplace=True)
            (3): FactorisedConv(
              (block): Sequential(
                (0): Conv2d(4, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
                (1): ReLU(inplace=True)
                (2): Conv2d(8, 8, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
                (3): ReLU(inplace=True)
              )
            )
            (4): FactorisedConv(
              (block): Sequential(
                (0): Conv2d(8, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
                (1): ReLU(inplace=True)
                (2): Conv2d(8, 8, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
                (3): ReLU(inplace=True)
              )
            )
          )
          (b3): Sequential(
            (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
            (1): Conv2d(8, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (2): Identity()
            (3): ReLU(inplace=True)
          )
          (dropout): Identity()
        )
      )
    )
    (1): InceptionStage(
      (stage): Sequential(
        (0): InceptionBlock(
          (b0): Sequential(
            (0): Conv2d(28, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): Identity()
            (2): ReLU(inplace=True)
          )
          (b1): Sequential(
            (0): Conv2d(28, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): Identity()
            (2): ReLU(inplace=True)
            (3): FactorisedConv(
              (block): Sequential(
                (0): Conv2d(4, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
                (1): ReLU(inplace=True)
                (2): Conv2d(8, 8, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
                (3): ReLU(inplace=True)
              )
            )
          )
          (b2): Sequential(
            (0): Conv2d(28, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): Identity()
            (2): ReLU(inplace=True)
            (3): FactorisedConv(
              (block): Sequential(
                (0): Conv2d(4, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
                (1): ReLU(inplace=True)
                (2): Conv2d(8, 8, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
                (3): ReLU(inplace=True)
              )
            )
            (4): FactorisedConv(
              (block): Sequential(
                (0): Conv2d(8, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
                (1): ReLU(inplace=True)
                (2): Conv2d(8, 8, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
                (3): ReLU(inplace=True)
              )
            )
          )
          (b3): Sequential(
            (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
            (1): Conv2d(28, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (2): Identity()
            (3): ReLU(inplace=True)
          )
          (dropout): Identity()
        )
        (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      )
    )
    (2): InceptionStage(
      (stage): Sequential(
        (0): InceptionBlock(
          (b0): Sequential(
            (0): Conv2d(28, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): Identity()
            (2): ReLU(inplace=True)
          )
          (b1): Sequential(
            (0): Conv2d(28, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): Identity()
            (2): ReLU(inplace=True)
            (3): FactorisedConv(
              (block): Sequential(
                (0): Conv2d(4, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
                (1): ReLU(inplace=True)
                (2): Conv2d(8, 8, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
                (3): ReLU(inplace=True)
              )
            )
          )
          (b2): Sequential(
            (0): Conv2d(28, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): Identity()
            (2): ReLU(inplace=True)
            (3): FactorisedConv(
              (block): Sequential(
                (0): Conv2d(4, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
                (1): ReLU(inplace=True)
                (2): Conv2d(8, 8, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
                (3): ReLU(inplace=True)
              )
            )
            (4): FactorisedConv(
              (block): Sequential(
                (0): Conv2d(8, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
                (1): ReLU(inplace=True)
                (2): Conv2d(8, 8, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
                (3): ReLU(inplace=True)
              )
            )
          )
          (b3): Sequential(
            (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
            (1): Conv2d(28, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (2): Identity()
            (3): ReLU(inplace=True)
          )
          (dropout): Identity()
        )
        (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      )
    )
  )
  (pool): AdaptiveAvgPool2d(output_size=1)
  (classifier): Classifier(
    (net): Sequential(
      (0): Linear(in_features=28, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.7, inplace=False)
      (3): Linear(in_features=1024, out_features=29, bias=True)
    )
  )
)
Overwriting model state from train_InceptionNet_mame.pth
Patience for early stopping: 50 epochs
Training for 50 epochs
Epoch 001/50: train_loss=3.3702 acc=0.037 | val_loss=3.3636 acc=0.054
Epoch 002/50: train_loss=3.3673 acc=0.034 | val_loss=3.3623 acc=0.040
Epoch 003/50: train_loss=3.3641 acc=0.037 | val_loss=3.3619 acc=0.034
Epoch 004/50: train_loss=3.3632 acc=0.038 | val_loss=3.3619 acc=0.034
Epoch 005/50: train_loss=3.3627 acc=0.036 | val_loss=3.3622 acc=0.034
Epoch 006/50: train_loss=3.3631 acc=0.037 | val_loss=3.3626 acc=0.034
Epoch 007/50: train_loss=3.3638 acc=0.035 | val_loss=3.3631 acc=0.034
Epoch 008/50: train_loss=3.3635 acc=0.036 | val_loss=3.3635 acc=0.034
Epoch 009/50: train_loss=3.3642 acc=0.037 | val_loss=3.3640 acc=0.034
Epoch 010/50: train_loss=3.3645 acc=0.036 | val_loss=3.3644 acc=0.034
Epoch 011/50: train_loss=3.3648 acc=0.035 | val_loss=3.3648 acc=0.034
Epoch 012/50: train_loss=3.3651 acc=0.036 | val_loss=3.3651 acc=0.034
Epoch 013/50: train_loss=3.3653 acc=0.036 | val_loss=3.3654 acc=0.034
Epoch 014/50: train_loss=3.3655 acc=0.037 | val_loss=3.3657 acc=0.034
Epoch 015/50: train_loss=3.3659 acc=0.036 | val_loss=3.3659 acc=0.034
Epoch 016/50: train_loss=3.3661 acc=0.036 | val_loss=3.3661 acc=0.034
Epoch 017/50: train_loss=3.3662 acc=0.037 | val_loss=3.3663 acc=0.034
Epoch 018/50: train_loss=3.3663 acc=0.038 | val_loss=3.3664 acc=0.034
Epoch 019/50: train_loss=3.3665 acc=0.037 | val_loss=3.3666 acc=0.034
Epoch 020/50: train_loss=3.3666 acc=0.038 | val_loss=3.3667 acc=0.034
Epoch 021/50: train_loss=3.3667 acc=0.037 | val_loss=3.3668 acc=0.034
Epoch 022/50: train_loss=3.3668 acc=0.038 | val_loss=3.3668 acc=0.034
Epoch 023/50: train_loss=3.3669 acc=0.035 | val_loss=3.3669 acc=0.034
Epoch 024/50: train_loss=3.3670 acc=0.036 | val_loss=3.3670 acc=0.034
Epoch 025/50: train_loss=3.3670 acc=0.036 | val_loss=3.3670 acc=0.034
Epoch 026/50: train_loss=3.3670 acc=0.037 | val_loss=3.3671 acc=0.034
Epoch 027/50: train_loss=3.3670 acc=0.039 | val_loss=3.3671 acc=0.034
Epoch 028/50: train_loss=3.3671 acc=0.038 | val_loss=3.3671 acc=0.034
Epoch 029/50: train_loss=3.3671 acc=0.036 | val_loss=3.3672 acc=0.035
Epoch 030/50: train_loss=3.3671 acc=0.038 | val_loss=3.3672 acc=0.036
Epoch 031/50: train_loss=3.3671 acc=0.035 | val_loss=3.3672 acc=0.037
Epoch 032/50: train_loss=3.3671 acc=0.037 | val_loss=3.3672 acc=0.036
Epoch 033/50: train_loss=3.3672 acc=0.038 | val_loss=3.3672 acc=0.035
Epoch 034/50: train_loss=3.3672 acc=0.041 | val_loss=3.3672 acc=0.039
Epoch 035/50: train_loss=3.3672 acc=0.038 | val_loss=3.3672 acc=0.044
Epoch 036/50: train_loss=3.3672 acc=0.037 | val_loss=3.3673 acc=0.046
Epoch 037/50: train_loss=3.3672 acc=0.041 | val_loss=3.3673 acc=0.043
Epoch 038/50: train_loss=3.3672 acc=0.040 | val_loss=3.3673 acc=0.046
Epoch 039/50: train_loss=3.3672 acc=0.045 | val_loss=3.3673 acc=0.046
Epoch 040/50: train_loss=3.3672 acc=0.046 | val_loss=3.3673 acc=0.052
Epoch 041/50: train_loss=3.3672 acc=0.045 | val_loss=3.3673 acc=0.062
Epoch 042/50: train_loss=3.3672 acc=0.044 | val_loss=3.3673 acc=0.062
Epoch 043/50: train_loss=3.3672 acc=0.045 | val_loss=3.3673 acc=0.061
Epoch 044/50: train_loss=3.3672 acc=0.047 | val_loss=3.3673 acc=0.057
Epoch 045/50: train_loss=3.3672 acc=0.045 | val_loss=3.3673 acc=0.047
Epoch 046/50: train_loss=3.3672 acc=0.046 | val_loss=3.3673 acc=0.039
Epoch 047/50: train_loss=3.3672 acc=0.046 | val_loss=3.3673 acc=0.037
Epoch 048/50: train_loss=3.3672 acc=0.042 | val_loss=3.3673 acc=0.034
Epoch 049/50: train_loss=3.3672 acc=0.043 | val_loss=3.3673 acc=0.034
Epoch 050/50: train_loss=3.3672 acc=0.043 | val_loss=3.3673 acc=0.034
Loading best model for final evaluation...
Test loss: 3.3673 | Test acc: 0.067

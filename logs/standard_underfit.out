Model: StandardCNN(
  (features): Sequential(
    (0): ConvBlock(
      (block): Sequential(
        (0): Conv2d(3, 4, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))
        (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
      )
    )
  )
  (pool): Sequential(
    (0): AdaptiveAvgPool2d(output_size=1)
    (1): Flatten(start_dim=1, end_dim=-1)
  )
  (classifier): Classifier(
    (net): Sequential(
      (0): Linear(in_features=4, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.7, inplace=False)
      (3): Linear(in_features=1024, out_features=29, bias=True)
    )
  )
)
Patience for early stopping: 50 epochs
Training for 50 epochs
Epoch 001/50: train_loss=3.3247 acc=0.061 | val_loss=3.2637 acc=0.068
Epoch 002/50: train_loss=3.1582 acc=0.073 | val_loss=3.0524 acc=0.095
Epoch 003/50: train_loss=2.9824 acc=0.108 | val_loss=2.9193 acc=0.142
Epoch 004/50: train_loss=2.8699 acc=0.152 | val_loss=2.8277 acc=0.186
Epoch 005/50: train_loss=2.7890 acc=0.170 | val_loss=2.7530 acc=0.196
Epoch 006/50: train_loss=2.7288 acc=0.185 | val_loss=2.6973 acc=0.203
Epoch 007/50: train_loss=2.6832 acc=0.196 | val_loss=2.6533 acc=0.218
Epoch 008/50: train_loss=2.6388 acc=0.207 | val_loss=2.6057 acc=0.227
Epoch 009/50: train_loss=2.6064 acc=0.208 | val_loss=2.5729 acc=0.228
Epoch 010/50: train_loss=2.5740 acc=0.218 | val_loss=2.5413 acc=0.224
Epoch 011/50: train_loss=2.5478 acc=0.219 | val_loss=2.5227 acc=0.231
Epoch 012/50: train_loss=2.5349 acc=0.226 | val_loss=2.5120 acc=0.228
Epoch 013/50: train_loss=2.5209 acc=0.226 | val_loss=2.4963 acc=0.230
Epoch 014/50: train_loss=2.5074 acc=0.228 | val_loss=2.4861 acc=0.228
Epoch 015/50: train_loss=2.5005 acc=0.232 | val_loss=2.4768 acc=0.248
Epoch 016/50: train_loss=2.4886 acc=0.236 | val_loss=2.4652 acc=0.234
Epoch 017/50: train_loss=2.4778 acc=0.236 | val_loss=2.4542 acc=0.238
Epoch 018/50: train_loss=2.4723 acc=0.236 | val_loss=2.4461 acc=0.241
Epoch 019/50: train_loss=2.4665 acc=0.240 | val_loss=2.4422 acc=0.240
Epoch 020/50: train_loss=2.4557 acc=0.241 | val_loss=2.4307 acc=0.239
Epoch 021/50: train_loss=2.4524 acc=0.241 | val_loss=2.4236 acc=0.239
Epoch 022/50: train_loss=2.4433 acc=0.243 | val_loss=2.4203 acc=0.244
Epoch 023/50: train_loss=2.4372 acc=0.248 | val_loss=2.4089 acc=0.243
Epoch 024/50: train_loss=2.4286 acc=0.249 | val_loss=2.4113 acc=0.246
Epoch 025/50: train_loss=2.4227 acc=0.248 | val_loss=2.3974 acc=0.248
Epoch 026/50: train_loss=2.4170 acc=0.250 | val_loss=2.3952 acc=0.250
Epoch 027/50: train_loss=2.4119 acc=0.251 | val_loss=2.3917 acc=0.248
Epoch 028/50: train_loss=2.4081 acc=0.249 | val_loss=2.3866 acc=0.253
Epoch 029/50: train_loss=2.4027 acc=0.254 | val_loss=2.3765 acc=0.252
Epoch 030/50: train_loss=2.3977 acc=0.256 | val_loss=2.3755 acc=0.257
Epoch 031/50: train_loss=2.3936 acc=0.257 | val_loss=2.3691 acc=0.258
Epoch 032/50: train_loss=2.3854 acc=0.259 | val_loss=2.3600 acc=0.261
Epoch 033/50: train_loss=2.3825 acc=0.258 | val_loss=2.3623 acc=0.259
Epoch 034/50: train_loss=2.3809 acc=0.259 | val_loss=2.3497 acc=0.269
Epoch 035/50: train_loss=2.3770 acc=0.262 | val_loss=2.3517 acc=0.256
Epoch 036/50: train_loss=2.3702 acc=0.263 | val_loss=2.3438 acc=0.265
Epoch 037/50: train_loss=2.3671 acc=0.263 | val_loss=2.3407 acc=0.257
Epoch 038/50: train_loss=2.3663 acc=0.261 | val_loss=2.3350 acc=0.268
Epoch 039/50: train_loss=2.3583 acc=0.268 | val_loss=2.3305 acc=0.267
Epoch 040/50: train_loss=2.3547 acc=0.267 | val_loss=2.3353 acc=0.264
Epoch 041/50: train_loss=2.3491 acc=0.265 | val_loss=2.3260 acc=0.267
Epoch 042/50: train_loss=2.3457 acc=0.272 | val_loss=2.3184 acc=0.266
Epoch 043/50: train_loss=2.3438 acc=0.271 | val_loss=2.3183 acc=0.276
Epoch 044/50: train_loss=2.3421 acc=0.273 | val_loss=2.3156 acc=0.277
Epoch 045/50: train_loss=2.3378 acc=0.272 | val_loss=2.3122 acc=0.273
Epoch 046/50: train_loss=2.3347 acc=0.272 | val_loss=2.3066 acc=0.277
Epoch 047/50: train_loss=2.3321 acc=0.273 | val_loss=2.3078 acc=0.273
Epoch 048/50: train_loss=2.3330 acc=0.276 | val_loss=2.3003 acc=0.277
Epoch 049/50: train_loss=2.3244 acc=0.277 | val_loss=2.2995 acc=0.278
Epoch 050/50: train_loss=2.3240 acc=0.276 | val_loss=2.2964 acc=0.281
Loading best model for final evaluation...
Test loss: 2.3423 | Test acc: 0.274

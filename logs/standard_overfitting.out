Model: StandardCNN(
  (features): Sequential(
    (0): ConvBlock(
      (block): Sequential(
        (0): Conv2d(3, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
    )
    (1): ConvBlock(
      (block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
    )
    (2): ConvBlock(
      (block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
    )
    (3): ConvBlock(
      (block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
    )
  )
  (pool): Identity()
  (classifier): Classifier(
    (net): Sequential(
      (0): Linear(in_features=32768, out_features=65536, bias=True)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.05, inplace=False)
      (3): Linear(in_features=65536, out_features=29, bias=True)
    )
  )
)
Epoch 001/50: train_loss=4.7275 acc=0.178 | val_loss=2.2195 acc=0.332
Epoch 002/50: train_loss=1.8024 acc=0.449 | val_loss=1.5654 acc=0.516
Epoch 003/50: train_loss=1.2281 acc=0.616 | val_loss=1.5051 acc=0.534
Epoch 004/50: train_loss=0.7229 acc=0.776 | val_loss=1.8115 acc=0.572
Epoch 005/50: train_loss=0.4139 acc=0.880 | val_loss=2.1076 acc=0.554
Epoch 006/50: train_loss=0.2624 acc=0.923 | val_loss=3.1547 acc=0.553
Epoch 007/50: train_loss=0.2037 acc=0.945 | val_loss=3.0752 acc=0.546
Epoch 008/50: train_loss=0.2081 acc=0.949 | val_loss=3.6255 acc=0.554
Epoch 009/50: train_loss=0.1515 acc=0.962 | val_loss=3.5720 acc=0.566
Epoch 010/50: train_loss=0.1569 acc=0.961 | val_loss=3.5898 acc=0.550
Epoch 011/50: train_loss=0.1103 acc=0.975 | val_loss=3.7702 acc=0.527
Epoch 012/50: train_loss=0.1081 acc=0.975 | val_loss=4.7208 acc=0.565
Epoch 013/50: train_loss=0.0953 acc=0.980 | val_loss=4.4260 acc=0.521
Epoch 014/50: train_loss=0.0819 acc=0.983 | val_loss=4.9308 acc=0.549
Epoch 015/50: train_loss=0.1005 acc=0.980 | val_loss=4.9320 acc=0.564
Epoch 016/50: train_loss=0.1035 acc=0.980 | val_loss=4.5601 acc=0.535
Epoch 017/50: train_loss=0.0765 acc=0.983 | val_loss=5.1148 acc=0.537
Epoch 018/50: train_loss=0.0937 acc=0.982 | val_loss=4.7897 acc=0.555
Epoch 019/50: train_loss=0.0637 acc=0.986 | val_loss=6.2256 acc=0.541
Epoch 020/50: train_loss=0.0876 acc=0.983 | val_loss=5.7425 acc=0.559
Epoch 021/50: train_loss=0.0564 acc=0.990 | val_loss=5.9101 acc=0.528
Epoch 022/50: train_loss=0.0733 acc=0.986 | val_loss=5.7869 acc=0.566
Epoch 023/50: train_loss=0.0511 acc=0.990 | val_loss=5.3325 acc=0.537
Epoch 024/50: train_loss=0.0589 acc=0.989 | val_loss=7.7719 acc=0.557
Early stopping triggered after 24 epochs with no improvement over 20.
Loading best model for final evaluation...
Test loss: 1.8946 | Test acc: 0.553
